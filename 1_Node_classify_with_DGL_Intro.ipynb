{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node classification with DGL, predicting the category of a Node in a graph\n",
    "* You will master:\n",
    "   1. Load a DGL-provided dataset\n",
    "   2. Build a GNN model with DGL-provided neural network modules\n",
    "   3. Train and evaluate a GNN model for node classification on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yht/anaconda3/envs/xmz/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GNN offers an ooportunity to obtain node representations by combing the connectivity and features of a local neighborhood\n",
    "* GNN 图神经网络能够通过整合领域节点和相应边的特征的特则来获取中心节点的表达\n",
    "* The next part will show how to build **a GNN for semi-supervised node classification** with only a small number of labels on the **Cora dataset**, a citation network **with papers as nodes** and **citations as edges**.\n",
    "* 这里介绍一个Cora图数据集，是一个关于论文引用的图网络数据库，paper作为顶点node，引用代表paper和paper之间的边"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This task is to predict the category of a given paper, **each paper node contains a word count vector as its features**, normalized so that they sum up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Number of categories:  7\n"
     ]
    }
   ],
   "source": [
    "import dgl.data\n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset()\n",
    "print(\"Number of categories: \", dataset.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 一个DGL数据集可能会包含一个或者多个图，但是这里的Cora数据集是只包含一张图的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=2708, num_edges=10556,\n",
      "      ndata_schemes={'feat': Scheme(shape=(1433,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'__orig__': Scheme(shape=(), dtype=torch.int64)})\n"
     ]
    }
   ],
   "source": [
    "g = dataset[0]\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A DGL graph can store node features and edge features in two dictionary-like attributes called ndata and edata.\n",
    "* The graph contains the following node features:\n",
    "   1. train_mask\n",
    "   2. val_mask\n",
    "   3. test_mask\n",
    "   4. label\n",
    "   5. feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features\n",
      "feat\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0526, 0.0000]])\n",
      "label\n",
      "tensor([4, 4, 4,  ..., 4, 3, 3])\n",
      "test_mask\n",
      "tensor([ True,  True, False,  ..., False, False, False])\n",
      "train_mask\n",
      "tensor([False, False, False,  ..., False, False, False])\n",
      "val_mask\n",
      "tensor([False, False,  True,  ..., False, False, False])\n"
     ]
    }
   ],
   "source": [
    "print('Node features')\n",
    "for k, v in g.ndata.items():\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 4, 4,  ..., 4, 3, 3])\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0526, 0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(g.ndata['label'])\n",
    "print(g.ndata['feat'])\n",
    "g.ndata['feat'].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* g.ndata['feat'].size() -> [2708, 1433] 这里的feature是一个 2708 * 1433，说明每个顶点的表示维度为1433，即每个顶点通过1433个特征来描述，一共2708个顶点，每个顶点是代表一篇paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a Graph Convolutional Network(GCN)\n",
    "* In the GCN, **each layer computes new node representations by aggregating neighbor information**.\n",
    "* 目前常见的类GCN模型，本质上都是在计算每个顶点的编码表示，有个模型会同时计算边的表示，最终就是为了抽取出更富有特征的顶点和边的向量表示，GCN可以看作是一种用于上游任务的编码器Encoder，而Node classification就是下游任务Decoder了。就类似CNN可以提取出更丰富的图像特征从而作为后期分类器的输入一样，本质上都是在做特征提取，获取更具有代表性的编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To build a multi-layer GCN you can simply stack dgl.nn.GraphConv modules, which **inherit torch.nn.Module**\n",
    "* 之前基于PyTorch复现了过GCN相关模型的paper，在类定义和API层面，GCN模型的构建大体上和其他神经网络差不多，都是继承nn.Module，然后写__init__() 和 forward()\n",
    "* 感觉这个DGL库就是将这些paper模型整合起来了，提供了统一的API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the GCN\n",
    "* DGL provides implementation of many popular neighbor aggregation modules\n",
    "* DGL 提供了许多顶点领域的聚合模型，每个聚合模型背后就是一篇paper吧哈哈\n",
    "* Training the GCN is similar to training other PyTorch neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "    \n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "\n",
    "    for e in range(100):\n",
    "        # Forward\n",
    "        logits = model(g, features)\n",
    "        \n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "        \n",
    "        # Compute loss\n",
    "        # 在训练集中计算每个节点的预测损失\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "        \n",
    "        # 在训练集测试集验证集上计算accuracy\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "        \n",
    "        # save the best validation acc and the correspongding test accracy\n",
    "        if best_val_acc < val_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_val_acc = val_acc\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if e % 5 == 0:\n",
    "            print(\"In epoch {}, loss: {:.3f}, val acc: {:.3f}(best: .3f), test acc:{:.3f}(best {:.3f})\".format(\n",
    "                e, loss, val_acc, best_val_acc, test_acc, best_test_acc, \n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 1.946, val acc: 0.172(best: .3f), test acc:0.172(best 0.160)\n",
      "In epoch 5, loss: 1.888, val acc: 0.650(best: .3f), test acc:0.650(best 0.677)\n",
      "In epoch 10, loss: 1.805, val acc: 0.672(best: .3f), test acc:0.672(best 0.674)\n",
      "In epoch 15, loss: 1.695, val acc: 0.710(best: .3f), test acc:0.710(best 0.701)\n",
      "In epoch 20, loss: 1.564, val acc: 0.722(best: .3f), test acc:0.722(best 0.729)\n",
      "In epoch 25, loss: 1.411, val acc: 0.724(best: .3f), test acc:0.724(best 0.732)\n",
      "In epoch 30, loss: 1.243, val acc: 0.740(best: .3f), test acc:0.740(best 0.726)\n",
      "In epoch 35, loss: 1.069, val acc: 0.742(best: .3f), test acc:0.746(best 0.727)\n",
      "In epoch 40, loss: 0.896, val acc: 0.754(best: .3f), test acc:0.754(best 0.736)\n",
      "In epoch 45, loss: 0.736, val acc: 0.762(best: .3f), test acc:0.762(best 0.751)\n",
      "In epoch 50, loss: 0.595, val acc: 0.768(best: .3f), test acc:0.772(best 0.756)\n",
      "In epoch 55, loss: 0.477, val acc: 0.766(best: .3f), test acc:0.772(best 0.764)\n",
      "In epoch 60, loss: 0.381, val acc: 0.766(best: .3f), test acc:0.772(best 0.769)\n",
      "In epoch 65, loss: 0.306, val acc: 0.770(best: .3f), test acc:0.772(best 0.768)\n",
      "In epoch 70, loss: 0.247, val acc: 0.766(best: .3f), test acc:0.772(best 0.767)\n",
      "In epoch 75, loss: 0.201, val acc: 0.772(best: .3f), test acc:0.772(best 0.769)\n",
      "In epoch 80, loss: 0.166, val acc: 0.772(best: .3f), test acc:0.772(best 0.766)\n",
      "In epoch 85, loss: 0.138, val acc: 0.772(best: .3f), test acc:0.772(best 0.768)\n",
      "In epoch 90, loss: 0.116, val acc: 0.770(best: .3f), test acc:0.772(best 0.767)\n",
      "In epoch 95, loss: 0.099, val acc: 0.770(best: .3f), test acc:0.772(best 0.767)\n"
     ]
    }
   ],
   "source": [
    "train(g, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = g.to('cuda')\n",
    "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 1.945, val acc: 0.190(best: .3f), test acc:0.190(best 0.168)\n",
      "In epoch 5, loss: 1.880, val acc: 0.594(best: .3f), test acc:0.594(best 0.609)\n",
      "In epoch 10, loss: 1.792, val acc: 0.646(best: .3f), test acc:0.646(best 0.664)\n",
      "In epoch 15, loss: 1.683, val acc: 0.678(best: .3f), test acc:0.680(best 0.690)\n",
      "In epoch 20, loss: 1.552, val acc: 0.714(best: .3f), test acc:0.714(best 0.712)\n",
      "In epoch 25, loss: 1.403, val acc: 0.726(best: .3f), test acc:0.728(best 0.727)\n",
      "In epoch 30, loss: 1.241, val acc: 0.732(best: .3f), test acc:0.732(best 0.737)\n",
      "In epoch 35, loss: 1.073, val acc: 0.734(best: .3f), test acc:0.738(best 0.733)\n",
      "In epoch 40, loss: 0.906, val acc: 0.734(best: .3f), test acc:0.738(best 0.737)\n",
      "In epoch 45, loss: 0.751, val acc: 0.742(best: .3f), test acc:0.742(best 0.738)\n",
      "In epoch 50, loss: 0.613, val acc: 0.744(best: .3f), test acc:0.746(best 0.736)\n",
      "In epoch 55, loss: 0.495, val acc: 0.750(best: .3f), test acc:0.750(best 0.748)\n",
      "In epoch 60, loss: 0.399, val acc: 0.756(best: .3f), test acc:0.756(best 0.748)\n",
      "In epoch 65, loss: 0.323, val acc: 0.752(best: .3f), test acc:0.756(best 0.756)\n",
      "In epoch 70, loss: 0.262, val acc: 0.754(best: .3f), test acc:0.756(best 0.755)\n",
      "In epoch 75, loss: 0.215, val acc: 0.762(best: .3f), test acc:0.762(best 0.758)\n",
      "In epoch 80, loss: 0.179, val acc: 0.766(best: .3f), test acc:0.766(best 0.760)\n",
      "In epoch 85, loss: 0.150, val acc: 0.774(best: .3f), test acc:0.774(best 0.760)\n",
      "In epoch 90, loss: 0.127, val acc: 0.770(best: .3f), test acc:0.774(best 0.759)\n",
      "In epoch 95, loss: 0.109, val acc: 0.770(best: .3f), test acc:0.774(best 0.757)\n"
     ]
    }
   ],
   "source": [
    "train(g, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a401e76bd4566b2eeae2d0101f096ff3c65dea3a493d427d71e4f6944057105a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('xmz')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
